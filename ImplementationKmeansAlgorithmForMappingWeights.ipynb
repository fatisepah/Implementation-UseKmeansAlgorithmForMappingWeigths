{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "BvbUV40_HLQm"
      },
      "outputs": [],
      "source": [
        "# Load in relevant libraries, and alias where appropriate\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "4vaW-d-6o1a-"
      },
      "outputs": [],
      "source": [
        "def zeropoint_quantize(X):\n",
        "    print(\"shapeX=\",X.shape)\n",
        "    # Calculate value range (denominator)\n",
        "    x_range = torch.max(X) - torch.min(X)\n",
        "    x_range = 1 if x_range == 0 else x_range\n",
        "\n",
        "    # Calculate scale\n",
        "    scale = 255 / x_range\n",
        "\n",
        "\n",
        "    # Scale and round the inputs\n",
        "    X_quant = torch.clip((X * scale ).round(), 0, 255)\n",
        "    print(\"shapeX_quant=\",X_quant.shape)\n",
        "    return X_quant.to(torch.int32),scale\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "z1o3zaoh_2pF"
      },
      "outputs": [],
      "source": [
        "def zeropoint_dequantize(X,scale):\n",
        "\n",
        "    # Dequantize\n",
        "    X_dequant = X / scale\n",
        "    print(\"shapeX_dequant=\",X_dequant.shape)\n",
        "    return  X_dequant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "LdrlawVt5Xfs"
      },
      "outputs": [],
      "source": [
        "XBit=8\n",
        "QBit=8\n",
        "QTZRange=2**QBit\n",
        "\n",
        "def DetectTheMidValueOfRange(WeightBuffer):\n",
        "    print(\"WeightBuffer=\",WeightBuffer.shape)\n",
        "    F = WeightBuffer.shape[0]\n",
        "    C = WeightBuffer.shape[1]\n",
        "    K = WeightBuffer.shape[2]\n",
        "\n",
        "    SumArrayF = np.zeros(F*C*K*K)\n",
        "    WeightBuffer=WeightBuffer.reshape(-1)\n",
        "    #print(\"WeightBuffer=\",WeightBuffer)\n",
        "    SumArrayF=WeightBuffer\n",
        "\n",
        "\n",
        "    #changing value of weightBuffer with the first value of each range\n",
        "    for w in range(F*C*K*K):\n",
        "      for x in range(QTZRange):\n",
        "          Pfirst=((x/QTZRange)*(2**XBit))\n",
        "          Plast=((x+1)/QTZRange)*(2**XBit)\n",
        "\n",
        "          if (SumArrayF[w]>=Pfirst) &  (SumArrayF[w]<Plast):\n",
        "              #the first value of each range\n",
        "              SumArrayF[w]=(Pfirst+Plast)/2\n",
        "              break\n",
        "    WeightBuffer=SumArrayF\n",
        "    WeightBuffer=WeightBuffer.reshape(F,C,K,K)\n",
        "    #print(\"WeightBuffer=\",WeightBuffer)\n",
        "\n",
        "    return WeightBuffer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "QBit=2\n",
        "QTZRange=2**QBit\n",
        "\n",
        "def QuantizeWithKmeansEachKernel(WeightBuffer):\n",
        "    F = WeightBuffer.shape[0]\n",
        "    C = WeightBuffer.shape[1]\n",
        "    K = WeightBuffer.shape[2]\n",
        "    for i in range(F):\n",
        "        for j in range(C):\n",
        "            layer=WeightBuffer[i,j,:].reshape(-1)\n",
        "            data =layer\n",
        "            #print(\"layer=\",layer)\n",
        "            kmeans = KMeans(n_clusters=QTZRange)\n",
        "            kmeans.fit(data.reshape(-1,1))\n",
        "            label=kmeans.labels_\n",
        "            #print(\"label=\",label)\n",
        "            layerk=torch.zeros(K*K)\n",
        "            for k in range(K*K):\n",
        "                layerk[k]=torch.tensor(kmeans.cluster_centers_[label[k]])\n",
        "\n",
        "            layerk=layerk.reshape(K,K)\n",
        "            WeightBuffer[i,j,:]=layerk\n",
        "            #print(\"layerk=\",layerk)\n",
        "    return WeightBuffer"
      ],
      "metadata": {
        "id": "m5m7CDZkVdt9"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "QBit=2\n",
        "QTZRange=2**QBit\n",
        "\n",
        "def QuantizeWithKmeansWholeFilter(WeightBuffer):\n",
        "    F = WeightBuffer.shape[0]\n",
        "    C = WeightBuffer.shape[1]\n",
        "    K = WeightBuffer.shape[2]\n",
        "    SumArrayF = np.zeros(F*C*K*K)\n",
        "    layer=WeightBuffer.reshape(-1)\n",
        "    data =layer\n",
        "    print(\"layer=\",layer)\n",
        "    kmeans = KMeans(n_clusters=QTZRange)\n",
        "    kmeans.fit(data.reshape(-1,1))\n",
        "    label=kmeans.labels_\n",
        "    print(\"label=\",label)\n",
        "    layerk=torch.zeros(F*C*K*K)\n",
        "    for k in range(F*C*K*K):\n",
        "        layerk[k]=torch.tensor(kmeans.cluster_centers_[label[k]])\n",
        "\n",
        "    layerk=layerk.reshape(F,C,K,K)\n",
        "    WeightBuffer=layerk\n",
        "    print(\"layerk=\",layerk)\n",
        "    return WeightBuffer"
      ],
      "metadata": {
        "id": "p1wIolkrkP8X"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-b2lsHe4Fpt",
        "outputId": "e2f0b567-d060-4ec9-f97a-c716db6577f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [400/938], Loss: 0.0389\n",
            "Epoch [1/10], Step [800/938], Loss: 0.0473\n",
            "WeightBuffer= torch.Size([6, 1, 5, 5])\n",
            "WeightBuffer= torch.Size([16, 6, 5, 5])\n",
            "WeightBuffer= torch.Size([120, 16, 5, 5])\n",
            "Epoch [2/10], Step [400/938], Loss: 2.3046\n",
            "Epoch [2/10], Step [800/938], Loss: 2.2988\n",
            "WeightBuffer= torch.Size([6, 1, 5, 5])\n",
            "WeightBuffer= torch.Size([16, 6, 5, 5])\n",
            "WeightBuffer= torch.Size([120, 16, 5, 5])\n",
            "Epoch [3/10], Step [400/938], Loss: 2.3169\n",
            "Epoch [3/10], Step [800/938], Loss: 2.2987\n",
            "WeightBuffer= torch.Size([6, 1, 5, 5])\n",
            "WeightBuffer= torch.Size([16, 6, 5, 5])\n",
            "WeightBuffer= torch.Size([120, 16, 5, 5])\n",
            "Epoch [4/10], Step [400/938], Loss: 2.2973\n",
            "Epoch [4/10], Step [800/938], Loss: 2.3024\n",
            "WeightBuffer= torch.Size([6, 1, 5, 5])\n",
            "WeightBuffer= torch.Size([16, 6, 5, 5])\n",
            "WeightBuffer= torch.Size([120, 16, 5, 5])\n",
            "Epoch [5/10], Step [400/938], Loss: 2.3038\n",
            "Epoch [5/10], Step [800/938], Loss: 2.3049\n",
            "WeightBuffer= torch.Size([6, 1, 5, 5])\n",
            "WeightBuffer= torch.Size([16, 6, 5, 5])\n",
            "WeightBuffer= torch.Size([120, 16, 5, 5])\n",
            "Epoch [6/10], Step [400/938], Loss: 2.3101\n",
            "Epoch [6/10], Step [800/938], Loss: 2.2930\n",
            "WeightBuffer= torch.Size([6, 1, 5, 5])\n",
            "WeightBuffer= torch.Size([16, 6, 5, 5])\n",
            "WeightBuffer= torch.Size([120, 16, 5, 5])\n",
            "Epoch [7/10], Step [400/938], Loss: 2.3004\n",
            "Epoch [7/10], Step [800/938], Loss: 2.3041\n",
            "WeightBuffer= torch.Size([6, 1, 5, 5])\n",
            "WeightBuffer= torch.Size([16, 6, 5, 5])\n",
            "WeightBuffer= torch.Size([120, 16, 5, 5])\n",
            "Epoch [8/10], Step [400/938], Loss: 2.3163\n",
            "Epoch [8/10], Step [800/938], Loss: 2.3075\n",
            "WeightBuffer= torch.Size([6, 1, 5, 5])\n",
            "WeightBuffer= torch.Size([16, 6, 5, 5])\n",
            "WeightBuffer= torch.Size([120, 16, 5, 5])\n",
            "Epoch [9/10], Step [400/938], Loss: 2.3048\n",
            "Epoch [9/10], Step [800/938], Loss: 2.3126\n",
            "WeightBuffer= torch.Size([6, 1, 5, 5])\n",
            "WeightBuffer= torch.Size([16, 6, 5, 5])\n",
            "WeightBuffer= torch.Size([120, 16, 5, 5])\n",
            "Epoch [10/10], Step [400/938], Loss: 2.3088\n",
            "Epoch [10/10], Step [800/938], Loss: 2.2963\n",
            "WeightBuffer= torch.Size([6, 1, 5, 5])\n",
            "WeightBuffer= torch.Size([16, 6, 5, 5])\n",
            "WeightBuffer= torch.Size([120, 16, 5, 5])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define relevant variables for the ML task\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "\n",
        "# Device will determine whether to run the training on GPU or CPU.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "#Loading the dataset and preprocessing\n",
        "train_dataset = torchvision.datasets.MNIST(root = './data',\n",
        "                                           train = True,\n",
        "                                           transform = transforms.Compose([\n",
        "                                                  transforms.Resize((32,32)),\n",
        "                                                  transforms.ToTensor(),\n",
        "                                                  transforms.Normalize(mean = (0.1307,), std = (0.3081,))]),\n",
        "                                           download = True)\n",
        "\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root = './data',\n",
        "                                          train = False,\n",
        "                                          transform = transforms.Compose([\n",
        "                                                  transforms.Resize((32,32)),\n",
        "                                                  transforms.ToTensor(),\n",
        "                                                  transforms.Normalize(mean = (0.1325,), std = (0.3105,))]),\n",
        "                                          download=True)\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                           batch_size = batch_size,\n",
        "                                           shuffle = True)\n",
        "\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                           batch_size = batch_size,\n",
        "                                           shuffle = True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Defining the convolutional neural network\n",
        "class LeNet5(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(LeNet5, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
        "        self.relu1=nn.ReLU()\n",
        "        self.maxpool1=nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "        self.relu2=nn.ReLU()\n",
        "        self.maxpool2=nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "        self.conv3 = nn.Conv2d(16, 120, kernel_size=5)\n",
        "\n",
        "        self.fc1 = nn.Linear(120, 84)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(84, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.maxpool1(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.maxpool2(out)\n",
        "        out = self.conv3(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu4(out)\n",
        "        out = self.fc2(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "model = LeNet5(num_classes).to(device)\n",
        "\n",
        "#Setting the loss function\n",
        "cost = nn.CrossEntropyLoss()\n",
        "\n",
        "#Setting the optimizer with the model parameters and learning rate\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "#this is defined to print how many steps are remaining when training\n",
        "total_step = len(train_loader)\n",
        "\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        #Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = cost(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "        if (i+1) % 400 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "        \t\t           .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "    #torch.save(model.state_dict(),'/content/drive/MyDrive/lenet-weight/weightsLenetPytorch3Conv-2.pt')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #print(\"model.state_dict()['conv1.weight']=\",model.state_dict()['conv1.weight'])\n",
        "    layer_weights1 = model.state_dict()['conv1.weight']\n",
        "    Conv1=DetectTheMidValueOfRange(layer_weights1)\n",
        "    model.state_dict()['conv1.weight'].data.copy_(Conv1)\n",
        "    #print(\"model.state_dict()['conv1.weight']=\",model.state_dict()['conv1.weight'])\n",
        "\n",
        "\n",
        "    layer_weights2 = model.state_dict()['conv2.weight']\n",
        "    Conv2=DetectTheMidValueOfRange(layer_weights2)\n",
        "    model.state_dict()['conv2.weight'].data.copy_(Conv2)\n",
        "\n",
        "\n",
        "    layer_weights3 = model.state_dict()['conv3.weight']\n",
        "    Conv3=DetectTheMidValueOfRange(layer_weights3)\n",
        "    model.state_dict()['conv3.weight'].data.copy_(Conv3)\n",
        "    #input()\n",
        "\n",
        "    #model.load_state_dict(torch.load('/content/drive/MyDrive/lenet-weight/weightsLenetPytorch3Conv-2.pt'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "P114BRl31JZe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2fb3747-b2a2-4e21-a616-be7af2201706"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 11.35 %\n"
          ]
        }
      ],
      "source": [
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "6h5AVP4v7WzO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "outputId": "0fb187e8-ac86-47b5-e703-ac3fc86bc6f4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-f245e352963b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'/content/drive/MyDrive/lenet-weight/weightsLenetPytorch3Conv-retrain-Kmeans8Q.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m             \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mcontainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_zipfile_writer_buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_zipfile_writer_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Parent directory /content/drive/MyDrive/lenet-weight does not exist."
          ]
        }
      ],
      "source": [
        "torch.save(model.state_dict(),'/content/drive/MyDrive/lenet-weight/weightsLenetPytorch3Conv-retrain-Kmeans8Q.pt')"
      ]
    }
  ]
}